{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.16.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.16.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchtext==0.16.0) (4.66.4)\n",
      "Requirement already satisfied: requests in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from torchtext==0.16.0) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchtext==0.16.0) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from torchtext==0.16.0) (1.26.1)\n",
      "Requirement already satisfied: torchdata==0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchtext==0.16.0) (0.7.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from torch==2.1.0->torchtext==0.16.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (2024.6.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from torchdata==0.7.0->torchtext==0.16.0) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from requests->torchtext==0.16.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from requests->torchtext==0.16.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from requests->torchtext==0.16.0) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from jinja2->torch==2.1.0->torchtext==0.16.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch==2.1.0->torchtext==0.16.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchtext==0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: portalocker==2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install portalocker==2.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (65.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.23.5)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "de_nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.transforms as T\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchtext.datasets.Multi30k(split = 'train')\n",
    "test_data = torchtext.datasets.Multi30k(split = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_target = []\n",
    "\n",
    "for data_idx,data in enumerate(data):\n",
    "  target = ' '.join(['sos',data[1],'eos'])\n",
    "  train_input.append(data[0])\n",
    "  train_target.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = []\n",
    "test_target = []\n",
    "\n",
    "for data_idx,data in enumerate(test_data):\n",
    "  target = ' '.join(['sos',data[1],'eos'])\n",
    "  test_input.append(data[0])\n",
    "  test_target.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Tokenization:\n",
    "  def __init__(self,nlp):\n",
    "    self.nlp = nlp\n",
    "\n",
    "  def _spacy_tokenizer(self,text):\n",
    "    return [token.text for token in self.nlp(text)]\n",
    "\n",
    "  def _yield_tokens(self,doc):\n",
    "    for text in doc:\n",
    "      text = self._spacy_tokenizer(text)\n",
    "      yield text\n",
    "\n",
    "  def _vocab(self,data):\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        self._yield_tokens(data),\n",
    "        specials = ['<pad>','<unk>']\n",
    "    )\n",
    "    vocab.set_default_index(vocab['<unk>'])\n",
    "    self.vocab = vocab\n",
    "\n",
    "\n",
    "  def tokenize(self,doc,maxlen,vocab = None):\n",
    "    if vocab == None:\n",
    "      self._vocab(doc)\n",
    "\n",
    "    transforms = T.Sequential(\n",
    "        T.VocabTransform(self.vocab),\n",
    "        T.Truncate(max_seq_len = maxlen),\n",
    "        T.ToTensor(padding_value = 0),\n",
    "        T.PadTransform(max_length = maxlen,pad_value = 0)\n",
    "    )\n",
    "\n",
    "    output = np.array([transforms(self._spacy_tokenizer(text)) for text in doc])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inputs_targets(sentences):\n",
    "  decoder_inputs = []\n",
    "  decoder_targets = [s[1:] for s in sentences]\n",
    "\n",
    "  for sentence in sentences:\n",
    "    sentence = [s for s in sentence if s != 0][:-1]\n",
    "    while len(sentence) != len(decoder_targets[0]): sentence.append(0)\n",
    "    decoder_inputs.append(np.array(sentence))\n",
    "\n",
    "  return np.array(decoder_inputs),np.array(decoder_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_jit_internal.py:1355: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "source_text_tokenizer = Text_Tokenization(de_nlp)\n",
    "target_text_tokenizer = Text_Tokenization(en_nlp)\n",
    "\n",
    "train_input_tokenized = source_text_tokenizer.tokenize(train_input[:1000],maxlen = 39)\n",
    "train_target_tokenized = target_text_tokenizer.tokenize(train_target[:1000],maxlen = 39)\n",
    "\n",
    "source_text_vocab = source_text_tokenizer.vocab\n",
    "source_text_inverse_vocab = {value:key for key,value in source_text_vocab.get_stoi().items()}\n",
    "\n",
    "target_text_vocab = target_text_tokenizer.vocab\n",
    "target_text_inverse_vocab = {value:key for key,value in target_text_vocab.get_stoi().items()}\n",
    "\n",
    "\n",
    "test_input_tokenized = source_text_tokenizer.tokenize(test_input[:3000],maxlen = 39,vocab = source_text_vocab)\n",
    "test_target_tokenized = target_text_tokenizer.tokenize(test_target[:3000],maxlen = 39,vocab = target_text_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input: [  20   89  282   33   96   19   54    6   12   63 2187  958    2    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Decoder input: [  4  18  26  16 574 729  15  54  59 307 452   5   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "Decoder target: [ 18  26  16 574 729  15  54  59 307 452   5   3   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "\n",
      "Encoder input reconstruction: Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche . \n",
      "Decoder input reconstruction: sos Two young , White males are outside near many bushes . \n",
      "Encoder reconstruction: Two young , White males are outside near many bushes . eos \n",
      "\n",
      "\n",
      "\n",
      "Test Encoder input: [  15   58   29 1325    1    1    7   18 1261    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Test Decoder input: [   4    6   56   13   40   15 1423 1153 1506    2  235    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "Test Decoder target: [   6   56   13   40   15 1423 1153 1506    2  235    3    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "Encoder input reconstruction: Eine Gruppe von Männern <unk> <unk> auf einen Lastwagen \n",
      "Decoder input reconstruction: sos A group of men are loading cotton onto a truck \n",
      "Encoder reconstruction: A group of men are loading cotton onto a truck eos \n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = train_input_tokenized\n",
    "decoder_inputs,decoder_targets = decoder_inputs_targets(train_target_tokenized)\n",
    "\n",
    "encoder_inputs_test = test_input_tokenized\n",
    "decoder_inputs_test,decoder_targets_test = decoder_inputs_targets(test_target_tokenized)\n",
    "\n",
    "print(f'Encoder input: {encoder_inputs[0]}')\n",
    "print(f'Decoder input: {decoder_inputs[0]}')\n",
    "print(f'Decoder target: {decoder_targets[0]}')\n",
    "\n",
    "\n",
    "print(f'\\nEncoder input reconstruction: {\" \".join([source_text_inverse_vocab[token] for token in encoder_inputs[0] if token != 0 ])} ')\n",
    "print(f'Decoder input reconstruction: {\" \".join([target_text_inverse_vocab[token] for token in decoder_inputs[0] if token != 0 ])} ')\n",
    "print(f'Encoder reconstruction: {\" \".join([target_text_inverse_vocab[token] for token in decoder_targets[0] if token != 0 ])} ')\n",
    "\n",
    "print(f'\\n\\n\\nTest Encoder input: {encoder_inputs_test[0]}')\n",
    "print(f'Test Decoder input: {decoder_inputs_test[0]}')\n",
    "print(f'Test Decoder target: {decoder_targets_test[0]}')\n",
    "\n",
    "print(f'\\nEncoder input reconstruction: {\" \".join([source_text_inverse_vocab[token] for token in encoder_inputs_test[0] if token != 0 ])} ')\n",
    "print(f'Decoder input reconstruction: {\" \".join([target_text_inverse_vocab[token] for token in decoder_inputs_test[0] if token != 0 ])} ')\n",
    "print(f'Encoder reconstruction: {\" \".join([target_text_inverse_vocab[token] for token in decoder_targets_test[0] if token != 0 ])} ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  15,   58,   29, 1325,    1,    1,    7,   18, 1261,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0]),\n",
       " tensor([   4,    6,   56,   13,   40,   15, 1423, 1153, 1506,    2,  235,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0]),\n",
       " tensor([   6,   56,   13,   40,   15, 1423, 1153, 1506,    2,  235,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "batched_encoder_inputs = DataLoader(encoder_inputs,batch_size)\n",
    "batched_decoder_inputs = DataLoader(decoder_inputs,batch_size)\n",
    "batched_decoder_targets = DataLoader(decoder_targets,batch_size)\n",
    "\n",
    "batched_encoder_inputs_test = DataLoader(encoder_inputs_test,batch_size)\n",
    "batched_decoder_inputs_test = DataLoader(decoder_inputs_test,batch_size)\n",
    "batched_decoder_targets_test = DataLoader(decoder_targets_test,batch_size)\n",
    "\n",
    "train_data_batched = DataLoader(list(zip(list(zip(encoder_inputs,decoder_inputs)),decoder_targets)),batch_size)\n",
    "test_data_batched = DataLoader(list(zip(list(zip(encoder_inputs_test,decoder_inputs_test)),decoder_targets_test)),batch_size)\n",
    "\n",
    "X,y = next(iter(train_data_batched))\n",
    "\n",
    "X[0][0],X[1][0],y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "  def __init__(self,vocab_size,embedding_size,hidden_size,num_layers,p):\n",
    "    super().__init__()\n",
    "\n",
    "    self.dropout = torch.nn.Dropout(p)\n",
    "    self.embedding = torch.nn.Embedding(vocab_size,embedding_size,padding_idx = 0)\n",
    "    self.lstm = torch.nn.LSTM(embedding_size,hidden_size,num_layers,batch_first = True,bidirectional = True,dropout = p)\n",
    "\n",
    "  def forward(self,encoder_input):\n",
    "    encoder_input = self.dropout(self.embedding(encoder_input))\n",
    "    _,(hidden,cell) = self.lstm(encoder_input)\n",
    "\n",
    "    return hidden,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "  def __init__(self,vocab_size,embedding_size,hidden_size,num_layers,p):\n",
    "    super().__init__()\n",
    "\n",
    "    self.dropout = torch.nn.Dropout(p)\n",
    "    self.embedding = torch.nn.Embedding(vocab_size,embedding_size,padding_idx = 0)\n",
    "    self.lstm = torch.nn.LSTM(embedding_size,hidden_size,num_layers,batch_first = True,bidirectional = True,dropout = p)\n",
    "    self.linear = torch.nn.Linear(2 * hidden_size,vocab_size)\n",
    "\n",
    "  def forward(self,decoder_input,input_hidden,input_cell):\n",
    "    decoder_input = self.dropout(self.embedding(decoder_input))\n",
    "\n",
    "    output,(decoder_hidden,decoder_cell) = self.lstm(decoder_input,(input_hidden,input_cell))\n",
    "    output = self.linear(output)\n",
    "\n",
    "    return output,decoder_hidden,decoder_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(torch.nn.Module):\n",
    "  def __init__(self,encoder,decoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def forward(self,X):\n",
    "    source,target = X\n",
    "\n",
    "    batch_size,target_seq_len = target.shape\n",
    "    target_vocab_size = len(target_text_inverse_vocab)\n",
    "    outputs = torch.zeros((target_seq_len,batch_size,target_vocab_size))\n",
    "\n",
    "    hidden,cell = self.encoder(source)\n",
    "\n",
    "    for token in range(0,target_seq_len):\n",
    "      output,hidden,cell = self.decoder(target[:,token].unsqueeze(1),hidden,cell)\n",
    "      outputs[token] = output.squeeze()\n",
    "\n",
    "    return outputs.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Model:\n",
    "  def __init__(self,model,loss_function,optimizer,epochs):\n",
    "    self.model = model\n",
    "    self.loss_function = loss_function\n",
    "    self.optimizer = optimizer\n",
    "    self.epochs = epochs\n",
    "\n",
    "\n",
    "  def _accuracy(self,target,prediction):\n",
    "    from sklearn.metrics import accuracy_score as accuracy\n",
    "    target = np.array(target).reshape(-1)\n",
    "    prediction = np.array(prediction).reshape(-1)\n",
    "\n",
    "    valid_idxs = np.argwhere(target != 0).reshape(-1)\n",
    "\n",
    "    target = target[valid_idxs]\n",
    "    prediction = prediction[valid_idxs]\n",
    "\n",
    "    acc = accuracy(target,prediction)\n",
    "\n",
    "    return acc\n",
    "\n",
    "  def fit(self,train_data_batched):\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    self.model.train()\n",
    "\n",
    "    train_batch_loss = 0\n",
    "    train_batch_acc = 0\n",
    "\n",
    "    for epoch in tqdm(range(self.epochs)):\n",
    "      for batch,(X,y) in tqdm(enumerate(train_data_batched)):\n",
    "        train_prediction = self.model(X)\n",
    "        train_labels = train_prediction.argmax(-1)\n",
    "\n",
    "        train_loss = self.loss_function(train_prediction.permute(0,2,1),y)\n",
    "        train_acc = self._accuracy(y,train_labels)\n",
    "\n",
    "        train_batch_loss += train_loss\n",
    "        train_batch_acc += train_acc\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "      train_batch_loss /= len(train_data_batched)\n",
    "      train_batch_acc /= len(train_data_batched)\n",
    "\n",
    "      print(f'Epoch: {epoch} | Train Loss: {train_batch_loss} | Train Accuracy: {train_batch_acc}')\n",
    "\n",
    "    return self.model\n",
    "\n",
    "\n",
    "  def eval(self,test_data_batched):\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    self.model.eval()\n",
    "\n",
    "    test_batch_loss = 0\n",
    "    test_batch_acc = 0\n",
    "\n",
    "    for batch,(X,y) in tqdm(enumerate(test_data_batched)):\n",
    "      test_prediction = self.model(X)\n",
    "      test_labels = test_prediction.argmax(-1)\n",
    "\n",
    "      test_loss = self.loss_function(test_prediction.permute(0,2,1),y)\n",
    "      test_acc = self._accuracy(y,test_labels)\n",
    "\n",
    "      test_batch_loss += test_loss\n",
    "      test_batch_acc += test_acc\n",
    "\n",
    "    test_batch_loss /= len(test_data_batched)\n",
    "    test_batch_acc /= len(test_data_batched)\n",
    "\n",
    "    print(f'Test Loss: {test_batch_loss} | Test Accuracy: {test_batch_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourve_vocab_size = len(source_text_inverse_vocab)\n",
    "target_vocab_size = len(target_text_inverse_vocab)\n",
    "\n",
    "embedding_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "p = 0.2\n",
    "\n",
    "encoder = Encoder(sourve_vocab_size,embedding_size,hidden_size,num_layers,p)\n",
    "decoder = Decoder(target_vocab_size,embedding_size,hidden_size,num_layers,p)\n",
    "model = Seq2Seq(encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514a30bedbad43f488176cedcba8d206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cafeafb15d44a4a5ef72e8e36daf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 3.2800869941711426 | Train Accuracy: 0.06191669889744503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f975f34e1b9742ac852960575fd1842a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 1.9530646800994873 | Train Accuracy: 0.21374264759008893\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148dfd8a643b4eaf80bf65e494db84dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 1.7931052446365356 | Train Accuracy: 0.26265276692912304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6979a350542d45ccbe0f3951dac48e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 1.7097806930541992 | Train Accuracy: 0.2804017549110527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e5e189b7b6450dbf777e3d5dcbd5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 1.6179306507110596 | Train Accuracy: 0.30661995502498407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e828b91ba8440a914ab2d303a38b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 1.5281482934951782 | Train Accuracy: 0.3291968737749158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68f6ec035fa411c8e6f2c5ff855a427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 1.4440710544586182 | Train Accuracy: 0.35066525247090546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e44c4f971041ad837d9e7eb10ead0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 1.3652151823043823 | Train Accuracy: 0.3701266853298629\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626dbaba5fca4f229b2ed52e258e2104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 1.2915691137313843 | Train Accuracy: 0.386556775069133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179ee17a66474ac89ec44b3cb3a13098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 1.225767731666565 | Train Accuracy: 0.3977846358468434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b84964540a4795aba8fc3dc612b258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 1.166143536567688 | Train Accuracy: 0.4153591455487834\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68eadf82322a41cea3c0bcae69e3bcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 1.08286714553833 | Train Accuracy: 0.43588392261010145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f7aac3bb954ea4b93cc1787504d342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 1.0109105110168457 | Train Accuracy: 0.45522864998618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001c895b76274c4f88a988d4877b8b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 0.9420673847198486 | Train Accuracy: 0.4779901650234873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ee6b6b74db4aa8a0c3e0ff1b9eba99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 0.8843963742256165 | Train Accuracy: 0.5026112578965313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e17bf13023a4b6a9c3cf7ca9fd10dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 0.8208913803100586 | Train Accuracy: 0.5299837168149873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f476027c95f4f878446278fb48f21f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 0.7549307942390442 | Train Accuracy: 0.5592042778855623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d835a791ee41c8b1d107f88e7e22ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss: 0.6910964846611023 | Train Accuracy: 0.5961160325296668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734f1750a1aa4de181ee69b968537f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss: 0.6267557144165039 | Train Accuracy: 0.6421945622196025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236338b44a1b479a8d65bc83f1c91a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss: 0.5653209686279297 | Train Accuracy: 0.6769753477955589\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b19f4f78d84eab8bd8cf98f7817a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss: 0.5195882320404053 | Train Accuracy: 0.7088854890115419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20411524e894d54962bd228d0df454b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss: 0.47199663519859314 | Train Accuracy: 0.74071255927118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192e5c285fd3448b91941cc66c5d80bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss: 0.4336816370487213 | Train Accuracy: 0.7656311625399638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c0bf5e70e243ff80076260022e62da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss: 0.3966355621814728 | Train Accuracy: 0.79059837128836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33764abae6d5400b8c6013c5b02f1606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss: 0.3475376069545746 | Train Accuracy: 0.8276025560276556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191c4f4fc64848cc9e21a5ba1b222262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train Loss: 0.3051137924194336 | Train Accuracy: 0.8631553673985932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a762b9e52d7b47189fb97b415ecc3e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train Loss: 0.2656541168689728 | Train Accuracy: 0.8972481197358971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ab2575e13c480a86bd1b00722bcc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train Loss: 0.22988465428352356 | Train Accuracy: 0.9211855839919622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392d2a6d63f54b0eb929f28db8c72404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train Loss: 0.20243416726589203 | Train Accuracy: 0.9406549099703587\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7586dc812ab4865ae46a475fcca3ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Train Loss: 0.17587482929229736 | Train Accuracy: 0.9574850840815399\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0690dbe81b1c417b90ae0db5f8f5e2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.8455290794372559 | Test Accuracy: 0.3794608507068989\n"
     ]
    }
   ],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "epochs = 30\n",
    "\n",
    "Trainer = Train_Model(model,loss_function,optimizer,epochs)\n",
    "model = Trainer.fit(train_data_batched)\n",
    "Trainer.eval(test_data_batched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Translate(model,text,source_text_vocab,source_text_tokenizer,target_text_inverse_vocab,max_translation_len = 30):\n",
    "  encoder = model.encoder\n",
    "  decoder = model.decoder\n",
    "\n",
    "  print(f'Input sentence: {text}')\n",
    "  text = torch.tensor(source_text_tokenizer.tokenize([text],39,source_text_vocab))\n",
    "\n",
    "  x = torch.tensor([[4]])\n",
    "  translation = []\n",
    "\n",
    "  hidden,cell = encoder(text)\n",
    "\n",
    "  for _ in range(max_translation_len):\n",
    "    output,hidden,cell = decoder(x,hidden,cell)\n",
    "    token = output.argmax(-1)\n",
    "    if token[0][0].item() == 3: break\n",
    "\n",
    "    translation.append(token[0][0].item())\n",
    "    x = token\n",
    "\n",
    "  translated_sentence = ' '.join([target_text_inverse_vocab[token] for token in translation])\n",
    "  print(f'Translated sentence: {translated_sentence}\\n')\n",
    "\n",
    "  return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Ein Hund spielt mit einem Schlauch.\n",
      "Translated sentence: A dog is playing with a hose .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A dog is playing with a hose .'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Translate(model,train_input[66],source_text_vocab,source_text_tokenizer,target_text_inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sos A dog is playing with a hose. eos'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
