{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.16.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.16.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchtext==0.16.0) (4.66.4)\n",
      "Requirement already satisfied: requests in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from torchtext==0.16.0) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchtext==0.16.0) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from torchtext==0.16.0) (1.26.1)\n",
      "Requirement already satisfied: torchdata==0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchtext==0.16.0) (0.7.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from torch==2.1.0->torchtext==0.16.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.1.0->torchtext==0.16.0) (2024.6.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from torchdata==0.7.0->torchtext==0.16.0) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from requests->torchtext==0.16.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from requests->torchtext==0.16.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from requests->torchtext==0.16.0) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nazarlenisin/Library/Python/3.11/lib/python/site-packages (from jinja2->torch==2.1.0->torchtext==0.16.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch==2.1.0->torchtext==0.16.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchtext==0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: portalocker==2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install portalocker==2.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (65.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.23.5)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nazarlenisin/anaconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 17:32:15.114331: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "de_nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchtext.datasets.Multi30k(split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_text = []\n",
    "en_text = []\n",
    "\n",
    "for data_idx,data in enumerate(data):\n",
    "  en = ' '.join(['<sos>',data[1],'<eos>'])\n",
    "  de_text.append(data[0])\n",
    "  en_text.append(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Tokenizer:\n",
    "  def __init__(self,nlp,tokenizer):\n",
    "    self.nlp = nlp\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def _spacy_tokenizer(self,text):\n",
    "    return [token.lemma_ for token in self.nlp(text)]\n",
    "\n",
    "  def _preprocess(self,text):\n",
    "      text = self._spacy_tokenizer(text)\n",
    "      return '|'.join(text)\n",
    "\n",
    "  def tokenize(self,doc,maxlen,fit = None):\n",
    "    doc = [self._preprocess(text) for text in doc]\n",
    "    if fit == None:\n",
    "      self.tokenizer.fit_on_texts(doc)\n",
    "\n",
    "    tokenized_text = self.tokenizer.texts_to_sequences(doc)\n",
    "\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self,encoder_vocab_size,embedding_size,hidden_size):\n",
    "    super().__init__()\n",
    "    self.encoder_vocab_size = encoder_vocab_size\n",
    "    self.embedding_size = embedding_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(encoder_vocab_size,embedding_size,mask_zero = True)\n",
    "    self.lstm = tf.keras.layers.LSTM(hidden_size,return_sequences = True,return_state = True)\n",
    "\n",
    "  def call(self,X):\n",
    "    #print(f'Encoder')\n",
    "    X = self.embedding(X)\n",
    "    #print(f'X: {X.shape}')\n",
    "    encoder_hidden_states,encoder_hidden,encoder_cell = self.lstm(X)\n",
    "    #print(f'Encoder hidden states: {encoder_hidden_states.shape}')\n",
    "    #print(f'Encoder hidden: {encoder_hidden.shape}')\n",
    "    #print(f'Encoder cell: {encoder_cell.shape}')\n",
    "\n",
    "    return encoder_hidden_states,encoder_hidden,encoder_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self,decoder_vocab_size,embedding_size,hidden_size):\n",
    "    super().__init__()\n",
    "    self.decoder_vocab_size = decoder_vocab_size\n",
    "    self.embedding_size = embedding_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(decoder_vocab_size,embedding_size,mask_zero = True)\n",
    "    self.lstm = tf.keras.layers.LSTM(hidden_size,return_sequences = True,return_state = True)\n",
    "    self.linear = tf.keras.layers.Dense(decoder_vocab_size,activation = 'softmax')\n",
    "\n",
    "  def call(self,X,encoder_states):\n",
    "    #print(f'\\n\\nDecoder')\n",
    "    encoder_hidden_states,encoder_hidden,encoder_cell = encoder_states\n",
    "    X = self.embedding(X)\n",
    "    #print(f'X: {X.shape}')\n",
    "\n",
    "    decoder_hidden_states,decoder_hidden,decoder_cell = self.lstm(X,(encoder_hidden,encoder_cell))\n",
    "    self.decoder_hidden = decoder_hidden\n",
    "    self.decoder_cell = decoder_cell\n",
    "    #print(f'Decoder hidden states: {decoder_hidden_states.shape}')\n",
    "    #print(f'Decoder hidden: {decoder_hidden.shape}')\n",
    "    #print(f'Decoder cell: {decoder_cell.shape}')\n",
    "\n",
    "    output = self.linear(decoder_hidden_states)\n",
    "    #print(f'Output: {output.shape}')\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(tf.keras.Model):\n",
    "  def __init__(self,encoder,decoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def call(self,data):\n",
    "    de_text,en_text = data\n",
    "    encoder_hidden_states,encoder_hidden,encoder_cell = self.encoder(de_text)\n",
    "    output = self.decoder(en_text,(encoder_hidden_states,encoder_hidden,encoder_cell))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Model:\n",
    "    def __init__(self,model,epochs,batch_size = 32):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def _accuracy(self,y,y_pred):\n",
    "        from sklearn.metrics import accuracy_score as accuracy\n",
    "        y = np.array(y).reshape(-1)\n",
    "        y_pred = np.array(y_pred).reshape(-1)\n",
    "        \n",
    "        accaptable_idxs = np.argwhere(y != 0).reshape(-1)\n",
    "        \n",
    "        y = y[accaptable_idxs]\n",
    "        y_pred = y_pred[accaptable_idxs]\n",
    "        \n",
    "        prediction_accuracy = accuracy(y,y_pred)\n",
    "        \n",
    "        return prediction_accuracy\n",
    "        \n",
    "         \n",
    "    def fit(self,X,y):\n",
    "        model = self.model\n",
    "        model.compile(\n",
    "            loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),\n",
    "        )\n",
    "\n",
    "        print(f'Loss on Train Data:')\n",
    "        model.fit(X,y,batch_size = self.batch_size,epochs = self.epochs)\n",
    "        self.model = model\n",
    "        train_prediction = tf.argmax(model(X),-1)\n",
    "        \n",
    "        train_accuracy = self._accuracy(y,train_prediction)\n",
    "        print(f'Accuracy on Train Data: {train_accuracy}')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def eval(self,X,y):\n",
    "        model = self.model\n",
    "        test_prediction = tf.argmax(model(X),-1)\n",
    "        test_accuracy = self._accuracy(y,test_prediction)\n",
    "        print(f'Accuracy on Test Data: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = len(max(de_text,key = len))\n",
    "\n",
    "de_tokenizer = Tokenizer(oov_token = '<unk>',split = '|')\n",
    "en_tokenizer = Tokenizer(oov_token = '<unk>',split = '|')\n",
    "\n",
    "\n",
    "de_text_tokenizer = Text_Tokenizer(de_nlp,de_tokenizer)\n",
    "en_text_tokenizer = Text_Tokenizer(en_nlp,en_tokenizer)\n",
    "\n",
    "de_text_tokenized = de_text_tokenizer.tokenize(de_text[:1000],maxlen)\n",
    "en_text_tokenized = en_text_tokenizer.tokenize(en_text[:1000],maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_text_input_tokenized = [s[:-1] for s in en_text_tokenized]\n",
    "en_text_target_tokenized = [s[1:] for s in en_text_tokenized]\n",
    "\n",
    "de_text_padded = tf.keras.utils.pad_sequences(de_text_tokenized,maxlen = maxlen,padding = 'post',truncating = 'post')\n",
    "en_text_input_padded = tf.keras.utils.pad_sequences(en_text_input_tokenized,maxlen = maxlen,padding = 'post',truncating = 'post')\n",
    "en_text_target_padded = tf.keras.utils.pad_sequences(en_text_target_tokenized,maxlen = maxlen,padding = 'post',truncating = 'post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 254)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_vocab_size = len(de_text_tokenizer.tokenizer.word_index) + 1\n",
    "decoder_vocab_size = len(en_text_tokenizer.tokenizer.word_index) + 1\n",
    "embedding_size = 128\n",
    "hidden_size = 128\n",
    "\n",
    "encoder = Encoder(encoder_vocab_size,embedding_size,hidden_size)\n",
    "decoder = Decoder(decoder_vocab_size,embedding_size,hidden_size)\n",
    "\n",
    "model = Seq2Seq(encoder,decoder)\n",
    "\n",
    "model((de_text_padded,en_text_input_padded)).shape\n",
    "\n",
    "de_text_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on Train Data:\n",
      "Epoch 1/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - loss: 6.0244\n",
      "Epoch 2/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 438ms/step - loss: 4.5140\n",
      "Epoch 3/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 452ms/step - loss: 3.9853\n",
      "Epoch 4/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 557ms/step - loss: 3.6830\n",
      "Epoch 5/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 573ms/step - loss: 3.3910\n",
      "Epoch 6/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 538ms/step - loss: 3.2259\n",
      "Epoch 7/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 541ms/step - loss: 3.0393\n",
      "Epoch 8/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 518ms/step - loss: 2.8629\n",
      "Epoch 9/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 541ms/step - loss: 2.6837\n",
      "Epoch 10/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 629ms/step - loss: 2.5286\n",
      "Epoch 11/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 765ms/step - loss: 2.3694\n",
      "Epoch 12/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 548ms/step - loss: 2.2614\n",
      "Epoch 13/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 496ms/step - loss: 2.1087\n",
      "Epoch 14/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 492ms/step - loss: 2.0005\n",
      "Epoch 15/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 518ms/step - loss: 1.8929\n",
      "Epoch 16/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 513ms/step - loss: 1.8143\n",
      "Epoch 17/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 503ms/step - loss: 1.6866\n",
      "Epoch 18/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 533ms/step - loss: 1.6105\n",
      "Epoch 19/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 535ms/step - loss: 1.5349\n",
      "Epoch 20/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 530ms/step - loss: 1.4663\n",
      "Epoch 21/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 524ms/step - loss: 1.3952\n",
      "Epoch 22/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 528ms/step - loss: 1.3270\n",
      "Epoch 23/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 544ms/step - loss: 1.2571\n",
      "Epoch 24/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 496ms/step - loss: 1.1944\n",
      "Epoch 25/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 560ms/step - loss: 1.1374\n",
      "Epoch 26/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 559ms/step - loss: 1.0997\n",
      "Epoch 27/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 536ms/step - loss: 1.0592\n",
      "Epoch 28/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 580ms/step - loss: 1.0064\n",
      "Epoch 29/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 563ms/step - loss: 0.9500\n",
      "Epoch 30/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 549ms/step - loss: 0.9177\n",
      "Epoch 31/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 565ms/step - loss: 0.8779\n",
      "Epoch 32/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 579ms/step - loss: 0.8344\n",
      "Epoch 33/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 584ms/step - loss: 0.7898\n",
      "Epoch 34/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 553ms/step - loss: 0.7435\n",
      "Epoch 35/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 572ms/step - loss: 0.7208\n",
      "Epoch 36/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 596ms/step - loss: 0.6800\n",
      "Epoch 37/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 572ms/step - loss: 0.6691\n",
      "Epoch 38/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 573ms/step - loss: 0.6385\n",
      "Epoch 39/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 596ms/step - loss: 0.6000\n",
      "Epoch 40/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 605ms/step - loss: 0.5706\n",
      "Epoch 41/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 613ms/step - loss: 0.5299\n",
      "Epoch 42/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 575ms/step - loss: 0.5188\n",
      "Epoch 43/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 627ms/step - loss: 0.5091\n",
      "Epoch 44/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 594ms/step - loss: 0.4914\n",
      "Epoch 45/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 586ms/step - loss: 0.4700\n",
      "Epoch 46/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 613ms/step - loss: 0.4382\n",
      "Epoch 47/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 598ms/step - loss: 0.4155\n",
      "Epoch 48/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 586ms/step - loss: 0.4045\n",
      "Epoch 49/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 627ms/step - loss: 0.3763\n",
      "Epoch 50/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 571ms/step - loss: 0.3585\n",
      "Accuracy on Train Data: 0.9270833333333334\n",
      "Accuracy on Test Data: 0.9270833333333334\n"
     ]
    }
   ],
   "source": [
    "X_train = [de_text_padded,en_text_input_padded]\n",
    "y_train = en_text_target_padded\n",
    "\n",
    "Trainer = Train_Model(model,epochs = 50)\n",
    "Trainer.fit(X_train,y_train)\n",
    "Trainer.eval(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence,source_tokenizer,encoder,target_tokenizer,decoder,max_translated_len = 30):\n",
    "    input_seq = source_tokenizer.tokenize([sentence],maxlen)\n",
    "    print(f'Input seq: {input_seq}')\n",
    "    tokenized = source_tokenizer.tokenizer.sequences_to_texts(input_seq)\n",
    "    \n",
    "    input_seq = tf.keras.utils.pad_sequences(input_seq,maxlen = maxlen,padding = 'post')\n",
    "    encoder_output,state_h,state_c = encoder.predict(input_seq)\n",
    "    \n",
    "    current_word = 'sos'\n",
    "    decoded_sentence = []\n",
    "    \n",
    "    while len(decoded_sentence) < max_translated_len:\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = target_tokenizer.tokenizer.word_index[current_word]\n",
    "    \n",
    "        prediction = decoder(target_seq,[encoder_output,state_h,state_c])\n",
    "        state_h = decoder.decoder_hidden\n",
    "        state_c = decoder.decoder_cell\n",
    "    \n",
    "        current_token_idx = np.argmax(prediction[0])\n",
    "    \n",
    "        current_word = target_tokenizer.tokenizer.index_word[current_token_idx]\n",
    "    \n",
    "        if (current_word == 'eos'):\n",
    "            break\n",
    "    \n",
    "        decoded_sentence.append(current_word)\n",
    "    \n",
    "    return tokenized[0],' '.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input seq: [[2, 5, 4, 40, 29, 2, 100, 31, 3, 45, 5, 13, 25, 249]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('ein mann in grün halten ein gitarre während der anderer mann sein hemd ansehen',\n",
       " 'a woman in a red shirt be under a blanket and sleep in a vehicle')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(de_text[5],de_text_tokenizer,model.encoder,en_text_tokenizer,model.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ein mann in grün halten ein gitarre während der anderer mann sein hemd ansehen']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_text_tokenizer.tokenizer.sequences_to_texts([[2, 5, 4, 40, 29, 2, 100, 31, 3, 45, 5, 13, 25, 249]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
